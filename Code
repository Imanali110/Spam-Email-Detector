import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import seaborn as sns

# Download NLTK stopwords
nltk.download('stopwords')

"""Load and Clean the Dataset"""

# Provide the path to your dataset
dataset_path = input("Enter the path to your dataset (CSV format): /content/spam.csv")
df = pd.read_csv(dataset_path, encoding='ISO-8859-1')

# Remove unnamed columns and rename
df.rename(columns={"v1": "Category", "v2": "Message"}, inplace=True)
df.drop(columns={'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'}, inplace=True)

# Create binary 'Spam' column
df['Spam'] = df['Category'].apply(lambda x: 1 if x == 'spam' else 0)

# Show the number of rows and columns
print("Number of rows and columns: ", df.shape)

# Show the number of duplicated values
print("Number of duplicated values: ", df.duplicated().sum())

"""Explore the Dataset after Cleaning"""

print("\nColumns after renaming and cleaning:")
print(df.columns.tolist())

# View the top 5 rows
print("Top 5 rows:")
print(df.head())

# View the bottom 5 rows
print("Bottom 5 rows:")
print(df.tail())

"""Check unique values"""

# Check Unique Values for each variable using a for loop.
for i in df.columns.tolist():
  print("No. of unique values in",i,"is",df[i].nunique())

"""Handle missing values

"""

# Check for missing values
print("\nMissing Values in Dataset:")
print(df.isnull().sum())

# Drop rows with missing values if necessary
df.dropna(inplace=True)

# Verify missing values are removed
print("\nDataset after dropping missing values:")
print(df.isnull().sum())

"""Summary Statistics"""

print("\nSummary Statistics:")
print(df.describe())

"""Visualise Data Distribution Via Pie Chart"""

# Pie Chart for Spam and Ham Distribution
spread = df['Category'].value_counts()
plt.figure(figsize=(5, 5))
spread.plot(kind='pie', autopct='%1.2f%%', cmap='Set1', labels=spread.index)
plt.title('Distribution of Spam vs Ham')
plt.ylabel('')
plt.show()

"""Text Preprocessing"""

# Text preprocessing
ps = PorterStemmer()
corpus = []
for i in range(len(df)):
    review = re.sub('[^a-zA-Z]', ' ', df['Message'][i])
    review = review.lower().split()
    review = [ps.stem(word) for word in review if word not in stopwords.words('english')]
    corpus.append(' '.join(review))

"""Most used words in Spam Emails"""

from collections import Counter
import matplotlib.pyplot as plt

# Filter messages classified as spam
spam_messages = df[df['Spam'] == 1]['Message']

# Preprocess the messages: Tokenization and cleaning
spam_words = []
for message in spam_messages:
    words = re.findall(r'\b\w+\b', message.lower())  # Extract words
    filtered_words = [word for word in words if word not in stopwords.words('english')]
    spam_words.extend(filtered_words)

# Count word frequencies
word_counts = Counter(spam_words)

# Get the top 20 most common words in spam messages
most_common_words = word_counts.most_common(20)

# Display the most common words
print("Most Frequently Used Words in Spam Emails:")
for word, count in most_common_words:
    print(f"{word}: {count}")

# Plot a bar chart of the most common words
words, counts = zip(*most_common_words)
plt.figure(figsize=(10, 6))
plt.barh(words, counts, color='red', alpha=0.7)
plt.title("Most Frequently Used Words in Spam Emails")
plt.xlabel("Frequency")
plt.ylabel("Words")
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.show()

"""Bag of Words Model and Train-Test Split"""

from collections import Counter
import matplotlib.pyplot as plt

# Filter messages classified as spam
spam_messages = df[df['Spam'] == 1]['Message']

# Preprocess the messages: Tokenization and cleaning
spam_words = []
for message in spam_messages:
    words = re.findall(r'\b\w+\b', message.lower())  # Extract words
    filtered_words = [word for word in words if word not in stopwords.words('english')]
    spam_words.extend(filtered_words)

# Count word frequencies
word_counts = Counter(spam_words)

# Get the top 20 most common words in spam messages
most_common_words = word_counts.most_common(20)

# Display the most common words
print("Most Frequently Used Words in Spam Emails:")
for word, count in most_common_words:
    print(f"{word}: {count}")

# Plot a bar chart of the most common words
words, counts = zip(*most_common_words)
plt.figure(figsize=(10, 6))
plt.barh(words, counts, color='red', alpha=0.7)
plt.title("Most Frequently Used Words in Spam Emails")
plt.xlabel("Frequency")
plt.ylabel("Words")
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.show()

# Bag of Words model
cv = CountVectorizer(max_features=4000)
X = cv.fit_transform(corpus).toarray()
Y = df['Spam'].values

# Split the dataset
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

"""Model Training"""

model1 = RandomForestClassifier()
model1.fit(X_train, Y_train)

model2 = DecisionTreeClassifier()
model2.fit(X_train, Y_train)

model3 = MultinomialNB()
model3.fit(X_train, Y_train)

# Predictions
pred1 = model1.predict(X_test)
pred2 = model2.predict(X_test)
pred3 = model3.predict(X_test)

"""Model Evaluation"""

# Evaluate Models
print("Random Forest Classifier")
print("Confusion Matrix: ", confusion_matrix(Y_test, pred1))
print("Accuracy: ", accuracy_score(Y_test, pred1))
print("--------------------------------")

print("Decision Tree Classifier")
print("Confusion Matrix: ", confusion_matrix(Y_test, pred2))
print("Accuracy: ", accuracy_score(Y_test, pred2))
print("--------------------------------")

print("Multinomial Naïve Bayes")
print("Confusion Matrix: ", confusion_matrix(Y_test, pred3))
print("Accuracy: ", accuracy_score(Y_test, pred3))
print("--------------------------------")

# Confusion Matrix Heatmap for Multinomial Naïve Bayes
cm = confusion_matrix(Y_test, pred3)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.show()

# Classification Reports
print("Classification Report for RFC\n", classification_report(Y_test, pred1))
print("Classification Report for DTC\n", classification_report(Y_test, pred2))
print("Classification Report for MNB\n", classification_report(Y_test, pred3))

"""Saving the models"""

# Save Models
pickle.dump(model1, open("RFC.pkl", 'wb'))
pickle.dump(model2, open("DTC.pkl", 'wb'))
pickle.dump(model3, open("MNB.pkl", 'wb'))
print("Models saved.")

"""Define and Test Email Spam Detection Function"""

# Load the Naive Bayes model for spam detection
clf = pickle.load(open("MNB.pkl", 'rb'))

# Defining a function for the Email Spam Detection System
def detect_spam(email_text):
    # Transform the email text using CountVectorizer
    transformed_text = cv.transform([email_text]).toarray()

    # Make a prediction
    prediction = clf.predict(transformed_text)

    if prediction == 0:
        return "This is a Ham Email!"
    else:
        return "This is a Spam Email!"

# Example of how to use the function
sample_email = 'Free Tickets for IPL'
result = detect_spam(sample_email)
print(result)

"""Linear Regression histogram of Residuals"""

# Calculate residuals
residuals = Y_test - pred3  # Using predictions from the Naive Bayes model

# Plot the histogram of residuals
plt.figure(figsize=(8, 6))
plt.hist(residuals, bins=15, color='blue', alpha=0.7, rwidth=0.85)
plt.title('Histogram of Residuals (Multinomial Naive Bayes)')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

"""Evaluation Metric Score Chart"""

# Function to Evaluate Model
def evaluate_model(clf, X_train, X_test, y_train, y_test):
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    return {"MSE": mse, "MAE": mae, "R^2": r2}

# Import required libraries
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Evaluate all models
RFC_scores = evaluate_model(model1, X_train, X_test, Y_train, Y_test)  # Random Forest
DTC_scores = evaluate_model(model2, X_train, X_test, Y_train, Y_test)  # Decision Tree
MultinomialNB_scores = evaluate_model(model3, X_train, X_test, Y_train, Y_test)  # Naive Bayes

# Visualize Evaluation Metric Scores (Line Graph)
def visualize_scores_line(models, scores, metrics):
    plt.figure(figsize=(10, 6))

    for model_name, score_dict in scores.items():
        values = [score_dict[metric] for metric in metrics]
        plt.plot(metrics, values, marker='o', label=model_name)

    plt.title('Evaluation Metric Scores (Line Graph)')
    plt.xlabel('Metrics')
    plt.ylabel('Score')
    plt.legend(loc='upper right')
    plt.grid(True)
    plt.show()

# Dictionary of model scores for visualization
model_scores = {
    "Random Forest": RFC_scores,
    "Decision Tree": DTC_scores,
    "Multinomial Naive Bayes": MultinomialNB_scores
}

# Metrics to display
metrics_list = ["MSE", "MAE", "R^2"]

# Call the visualization function
visualize_scores_line(models=["RFC", "DTC", "NB"], scores=model_scores, metrics=metrics_list)
